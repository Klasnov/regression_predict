{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvPpBknh51sa"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20707,
     "status": "ok",
     "timestamp": 1731209889407,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "0fGIbdUs51st",
    "outputId": "de347a19-9403-4571-a0c9-ad3bdb58d4bc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1731213726411,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "NzDGb9kI51sy",
    "outputId": "b0e726c9-4f3c-4190-f3c0-05ebc0c250d7"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/CS5228_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSmgUIYj51s1"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coTw0QB726Dl"
   },
   "source": [
    "## 1. Load in the dataset and remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1731213739206,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "z3dmHCks51s4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Remove the features that:\n",
    "      1. may not be so useful for the model\n",
    "      2. have too many missing values\n",
    "      3. all the values are the same\n",
    "      4. may be redundant with other features\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop([\"indicative_price\", \"eco_category\", \"opc_scheme\", \"lifespan\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = load_data(\"data/train.csv\")\n",
    "df_test = load_data(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmMKwJ0u51s7"
   },
   "source": [
    "## 2. Process date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1731213739506,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "LkCnhhPY51s9"
   },
   "outputs": [],
   "source": [
    "def proce_date(df):\n",
    "    \"\"\"\n",
    "    Convert the date imformation from string to duration numerical number\n",
    "    \"\"\"\n",
    "    # Convert date columns to datetime\n",
    "    df[\"reg_date\"] = pd.to_datetime(df[\"reg_date\"], format=\"%d-%b-%Y\")\n",
    "    df[\"original_reg_date\"] = pd.to_datetime(df[\"original_reg_date\"], format=\"%d-%b-%Y\")\n",
    "\n",
    "    # Calculate age of vehicle\n",
    "    end_date = pd.to_datetime(\"2024-11-01\")\n",
    "    reg_age = round(((end_date - df[\"reg_date\"]).dt.days / 365.25), 2)\n",
    "\n",
    "    # Fill missing values in manufactured column\n",
    "    df.loc[df[\"category\"].str.contains(\"parf car\"), \"manufactured\"] = df.loc[\n",
    "        df[\"category\"].str.contains(\"parf car\"), \"manufactured\"\n",
    "    ].fillna(df[\"reg_date\"].dt.year)\n",
    "\n",
    "    # Fill missing values in manufactured column\n",
    "    df.loc[df[\"manufactured\"].isna(), \"manufactured\"] = (\n",
    "        df.loc[df[\"manufactured\"].isna(), \"manufactured\"]\n",
    "        .fillna(df[\"original_reg_date\"].dt.year)\n",
    "        .fillna(df[\"reg_date\"].dt.year)\n",
    "    )\n",
    "    df[\"manufactured\"] = 2024 - df[\"manufactured\"]\n",
    "\n",
    "    # Drop and rename columns\n",
    "    df[\"reg_date\"] = reg_age\n",
    "    df.rename(columns={\"reg_date\": \"reg_age\"}, inplace=True)\n",
    "    df.drop([\"original_reg_date\"], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = proce_date(df_train)\n",
    "df_test = proce_date(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFUzQ-H2J5RC"
   },
   "source": [
    "## 3. Fill the missing `fuel_type` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731213739506,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "GPJJ-KR2PVb0",
    "outputId": "9555903c-6d62-4e9c-bbcc-b5ea5319a212"
   },
   "outputs": [],
   "source": [
    "# check for unseen fuel type\n",
    "unseen_fuel = set(df_test[\"fuel_type\"].unique()) - set(df_train[\"fuel_type\"].unique())\n",
    "print(len(unseen_fuel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1731213739935,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "lJxYp-Sq_eNE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_feature_distribution(df_train, df_test, feature_name, feature_labels=None):\n",
    "    \"\"\"\n",
    "    Plots the distribution of a feature (e.g., 'fuel_type') across training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train: The training dataset (DataFrame).\n",
    "    - df_test: The testing dataset (DataFrame).\n",
    "    - feature_name: The feature name (column) for which to plot the distribution.\n",
    "    - feature_labels: Optional dictionary with custom labels for the feature values.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Calculate the feature value counts as percentages for both train and test sets\n",
    "    train_feature_counts = df_train[feature_name].value_counts(normalize=True) * 100\n",
    "    test_feature_counts = df_test[feature_name].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Combine the results into a single DataFrame\n",
    "    combined_feature_counts = pd.DataFrame({\n",
    "        f'{feature_name}_train_percentage': train_feature_counts,\n",
    "        f'{feature_name}_test_percentage': test_feature_counts\n",
    "    }).fillna(0)\n",
    "\n",
    "    # Reset the index to use feature values as a column for plotting\n",
    "    combined_feature_counts.reset_index(inplace=True)\n",
    "    combined_feature_counts.columns = [feature_name, f'{feature_name}_train_percentage', f'{feature_name}_test_percentage']\n",
    "\n",
    "    # Melt the DataFrame for plotting\n",
    "    melted_df = combined_feature_counts.melt(id_vars=feature_name, value_vars=[f'{feature_name}_train_percentage', f'{feature_name}_test_percentage'],\n",
    "                                             var_name='Dataset', value_name='Percentage')\n",
    "\n",
    "    # Plot the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=feature_name, y='Percentage', hue='Dataset', data=melted_df)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(f'{feature_name.capitalize()} Distribution: Train vs Test', fontsize=16)\n",
    "    plt.xlabel(feature_name.capitalize(), fontsize=12)\n",
    "    plt.ylabel('Percentage (%)', fontsize=12)\n",
    "\n",
    "    if feature_labels:\n",
    "        plt.xticks(ticks=range(len(feature_labels)), labels=[feature_labels.get(val, val) for val in combined_feature_counts[feature_name]])\n",
    "    else:\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1731213741041,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "qUDjYE_G-uyQ",
    "outputId": "a80ec253-b8c6-4905-e019-db406635519f"
   },
   "outputs": [],
   "source": [
    "# plotting the distributions before imputation\n",
    "plot_feature_distribution(df_train, df_test, 'fuel_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1731213741042,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "30MDq-PIEZMp",
    "outputId": "9c2b23f3-f839-4397-ba3c-6c316f1b6e68"
   },
   "outputs": [],
   "source": [
    "# diesel is very frequent in this dataset, eventhough that is not the case in the population distribution by fuel type across singapore\n",
    "# let's take a closer look at the distribution in this dataset\n",
    "\n",
    "def analyze_diesel_distribution(df_train, df_test):\n",
    "    # Filter for diesel vehicles in both train and test sets\n",
    "    train_diesel = df_train[df_train[\"fuel_type\"].str.lower() == \"diesel\"]\n",
    "    test_diesel = df_test[df_test[\"fuel_type\"].str.lower() == \"diesel\"]\n",
    "\n",
    "    # Group by type_of_vehicle and count occurrences in each dataset\n",
    "    train_diesel_dist = (\n",
    "        train_diesel.groupby(\"type_of_vehicle\")[\"fuel_type\"]\n",
    "        .count()\n",
    "        .reset_index(name=\"train_count\")\n",
    "    )\n",
    "    test_diesel_dist = (\n",
    "        test_diesel.groupby(\"type_of_vehicle\")[\"fuel_type\"]\n",
    "        .count()\n",
    "        .reset_index(name=\"test_count\")\n",
    "    )\n",
    "\n",
    "    # Merge results for side-by-side comparison\n",
    "    diesel_distribution = pd.merge(\n",
    "        train_diesel_dist, test_diesel_dist, on=\"type_of_vehicle\", how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    return diesel_distribution.sort_values(by=\"train_count\", ascending=False)\n",
    "\n",
    "# Usage\n",
    "diesel_distribution_df = analyze_diesel_distribution(df_train, df_test)\n",
    "diesel_distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1731213741903,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "G29kwLlN_RCj",
    "outputId": "e1c673c4-e02b-47e2-92ac-ce8a9191b41a"
   },
   "outputs": [],
   "source": [
    "plot_feature_distribution(df_train, df_test, 'type_of_vehicle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1731213742856,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "BwD_liulxctU",
    "outputId": "ef0925f6-7036-4a11-8e21-f9da54ec24e3"
   },
   "outputs": [],
   "source": [
    "def build_condition(df, columns, keywords):\n",
    "    \"\"\"\n",
    "    Build a condition to check if any of the keywords are present in specified columns.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to search within\n",
    "    - columns: list of column names to search\n",
    "    - keywords: list of keywords to search for\n",
    "\n",
    "    Returns:\n",
    "    - Boolean Series representing the condition\n",
    "    \"\"\"\n",
    "    condition = None\n",
    "    keyword_pattern = \"|\".join(keywords)  # Create a regex pattern from keywords\n",
    "\n",
    "    # Loop through each column and build conditions\n",
    "    for col in columns:\n",
    "        col_condition = df[col].str.lower().str.contains(keyword_pattern, na=False)\n",
    "        condition = col_condition if condition is None else condition | col_condition\n",
    "\n",
    "    return condition\n",
    "\n",
    "def process_fuel_type(df):\n",
    "    # Define lists of keywords for different fuel types\n",
    "    hybrid_keywords = [\"hybrid\", \"hybrid engine\"]\n",
    "    misleading_hybrid_kw = [\"hybrid turbo\", \"hybrid racing\"]\n",
    "\n",
    "    # Define columns to search within\n",
    "    free_text_columns = [\"title\", \"features\", \"description\", \"category\"]\n",
    "\n",
    "    # Build the conditions using the new function\n",
    "    hybrid_freetext = build_condition(df, [\"features\", \"description\"], [\"hybrid\"])\n",
    "    hybrid_indicators = (build_condition(df, [\"title\", \"category\"], [\"hybrid\"]) | build_condition(df, [\"features\", \"description\"], [\"hybrid engine\",\"hybrid-engine\"]))\n",
    "    petrol_condition = build_condition(df, free_text_columns, [\"petrol\"])\n",
    "    diesel_condition = build_condition(df, free_text_columns, [\"diesel\"])\n",
    "    diesel_electric_condition = build_condition(df, free_text_columns, [\"diesel electric\", \"diesel-electric\"])\n",
    "    petrol_electric_condition = build_condition(df, free_text_columns, [\"petrol electric\", \"petrol-electric\"])\n",
    "\n",
    "    # Identify misleading hybrid entries, i.e. building a blacklist of non-hybrid entries listing ids\n",
    "    potential_hybrid = df[hybrid_freetext & ~hybrid_indicators]\n",
    "    misleading_hybrid_condition = build_condition(potential_hybrid, [\"features\", \"description\"], misleading_hybrid_kw)\n",
    "    non_hybrid = potential_hybrid[misleading_hybrid_condition]\n",
    "\n",
    "    # Define main hybrid, diesel, and electric conditions\n",
    "    hybrid_condition = (hybrid_freetext | hybrid_indicators) & ~(\n",
    "        df[\"listing_id\"].isin(non_hybrid[\"listing_id\"])\n",
    "    )\n",
    "    electric_indicators = build_condition(df, [\"title\", \"category\"], [\"electric\"])\n",
    "\n",
    "    # printing out the count before filling in\n",
    "    print(f\"# of non-hybrid vehicles with keyword hybrid: {non_hybrid.shape[0]}\")\n",
    "    print(f\"# of vehicles with diesel-electric keyword with nan fuel type: {df.loc[diesel_electric_condition & (df['fuel_type'].isna())].shape[0]}\")\n",
    "    print(f\"# of vehicles with electric keyword with nan fuel type: {df.loc[electric_indicators & (df['fuel_type'].isna())].shape[0]}\")\n",
    "    print(f\"# of vehicles with diesel keyword with nan fuel type: {df.loc[diesel_condition & (df['fuel_type'].isna())].shape[0]}\")\n",
    "    print(f\"# of vehicles with petrol-electric keyword with nan fuel type: {df.loc[(hybrid_condition | petrol_condition | petrol_electric_condition)& df['fuel_type'].isna()].shape[0]}\")\n",
    "\n",
    "    # Assign fuel types based on conditions\n",
    "    df.loc[electric_indicators & (df[\"fuel_type\"].isna()), \"fuel_type\"] = \"electric\"\n",
    "    df.loc[diesel_condition & df[\"fuel_type\"].isna(), \"fuel_type\"] = \"diesel\"\n",
    "    df.loc[diesel_electric_condition & df[\"fuel_type\"].isna(),\n",
    "        \"fuel_type\",\n",
    "    ] = \"diesel-electric\"\n",
    "    df.loc[\n",
    "        (hybrid_condition | petrol_condition | petrol_electric_condition)\n",
    "        & df[\"fuel_type\"].isna(),\n",
    "        \"fuel_type\",\n",
    "    ] = \"petrol-electric\"\n",
    "\n",
    "    # Fill any remaining NaNs with \"petrol\"\n",
    "    df[\"fuel_type\"] = df[\"fuel_type\"].fillna(\"petrol\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to both train and test datasets\n",
    "print(\"###Training###\")\n",
    "df_train = process_fuel_type(df_train)\n",
    "print(\"\\n###Testing###\")\n",
    "df_test = process_fuel_type(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1731213744368,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "WvHlGdGD9KzV",
    "outputId": "0c2607ca-6039-4168-b001-d8739151590d"
   },
   "outputs": [],
   "source": [
    "# plotting the distribution after imputation\n",
    "plot_feature_distribution(df_train, df_test, 'fuel_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731213744368,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "K1K1NnSWMiL6",
    "outputId": "1708b9bb-8d43-452a-f9b4-8f2b3fa32d3d"
   },
   "outputs": [],
   "source": [
    "# complete the ground truth stats for comparison and insights\n",
    "# https://www.lta.gov.sg/content/dam/ltagov/who_we_are/statistics_and_publications/statistics/pdf/MVP01-4_MVP_by_fuel.pdf\n",
    "\n",
    "data = {\n",
    "    'Year': [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023],\n",
    "    'Petrol': [612654, 605511, 587900, 578977, 574443, 569673, 574967, 572132, 568376, 558729, 540605],\n",
    "    'Diesel': [1412, 3206, 5976, 10364, 15514, 17253, 18049, 18076, 18136, 18261, 18037],\n",
    "    'Petrol-Electric': [5020, 5727, 6371, 10075, 20751, 27179, 35718, 41845, 54820, 65882, 79256],\n",
    "    'Petrol-Electric (Plug-In)': [None, 47, 108, 125, 206, 380, 473, 552, 692, 1101, 1359],\n",
    "    'Petrol-CNG': [2253, 2100, 1932, 1682, 1006, 386, 250, 202, 164, 143, 85],\n",
    "    'CNG': [None, None, None, None, None, None, None, None, None, None, None],\n",
    "    'Electric': [None, 1, 1, 12, 314, 560, 1120, 1217, 2942, 6531, 11941],\n",
    "    'Diesel-Electric': [6, 17, 23, 22, 22, 21, 19, 18, 20, 19, 18],\n",
    "    'Diesel-Electric (Plug-In)': [None, None, None, None, None, None, None, None, None, 1, 1],\n",
    "    'Total': [621345, 616609, 602311, 601257, 612256, 615452, 630596, 634042, 645150, 650667, 651302]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "stats = pd.DataFrame(data, index=data['Year']).drop(columns=['Year'])\n",
    "\n",
    "stats = stats.fillna(0)\n",
    "\n",
    "stats[\"Petrol-Electric\"] = stats[\"Petrol-Electric\"] + stats[\"Petrol-Electric (Plug-In)\"]\n",
    "stats[\"Diesel-Electric\"] = stats[\"Diesel-Electric\"] + stats[\"Diesel-Electric (Plug-In)\"]\n",
    "\n",
    "stats.drop(columns=[\"Petrol-Electric (Plug-In)\", \"Diesel-Electric (Plug-In)\"], inplace=True)\n",
    "\n",
    "stats[\"Petrol-Electric\"] = stats[\"Petrol-Electric\"].astype(int)\n",
    "stats[\"Diesel-Electric\"] = stats[\"Diesel-Electric\"].astype(int)\n",
    "stats[\"Electric\"] = stats[\"Electric\"].astype(int)\n",
    "\n",
    "# Calculate percentage for each fuel type\n",
    "stats_percentage = stats.copy()\n",
    "for column in stats.columns[:]:\n",
    "    stats_percentage[column] = round((stats[column] / stats['Total']) * 100, 2)\n",
    "\n",
    "lta_stats = stats_percentage.mean().reset_index().rename(columns={\"index\":\"fuel_type\", 0:\"lta_stats\"})\n",
    "lta_stats[\"fuel_type\"] = lta_stats[\"fuel_type\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1731213745131,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "CuAo9mdfAo4d",
    "outputId": "2552716e-515b-4a7b-9517-6dfad2b1aa6c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_comparison_side_by_side_with_labels(df_train, df_test, lta_stats):\n",
    "    \"\"\"\n",
    "    Plots a side-by-side bar chart comparing postprocessed stats (df_train and df_test) vs LTA stats for each fuel type,\n",
    "    with labels showing the values on top of each bar.\n",
    "\n",
    "    Parameters:\n",
    "    - df_train: DataFrame containing the training dataset.\n",
    "    - df_test: DataFrame containing the testing dataset.\n",
    "    - lta_stats: DataFrame containing LTA statistics.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Extract fuel type proportions from df_train and df_test\n",
    "    train_stats = df_train['fuel_type'].value_counts(normalize=True) * 100\n",
    "    test_stats = df_test['fuel_type'].value_counts(normalize=True) * 100\n",
    "\n",
    "    # Merge the stats into a single DataFrame\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'fuel_type': train_stats.index,\n",
    "        'train_stats': train_stats.values,\n",
    "        'test_stats': test_stats.values\n",
    "    }).fillna(0)\n",
    "\n",
    "    # Merge with LTA stats (ensure consistency in fuel type names)\n",
    "    comparison_df = comparison_df.merge(lta_stats, on='fuel_type', how='left')\n",
    "\n",
    "    # Set up the figure and axis\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.25\n",
    "\n",
    "    # Set the positions of the bars for train_stats, test_stats, and lta_stats\n",
    "    indices = np.arange(len(comparison_df))  # Position of each fuel type on the x-axis\n",
    "    train_pos = indices - bar_width  # Shift train stats to the left\n",
    "    test_pos = indices  # Test stats in the center\n",
    "    lta_pos = indices + bar_width  # Shift LTA stats to the right\n",
    "\n",
    "    # Plot the train_stats, test_stats, and lta_stats as bars\n",
    "    bars_train = plt.bar(train_pos, comparison_df['train_stats'], width=bar_width, label='Train Stats')\n",
    "    bars_test = plt.bar(test_pos, comparison_df['test_stats'], width=bar_width, label='Test Stats')\n",
    "    bars_lta = plt.bar(lta_pos, comparison_df['lta_stats'], width=bar_width, label='LTA Stats')\n",
    "\n",
    "    # Add value labels on top of the bars\n",
    "    for bar in bars_train:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    for bar in bars_test:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    for bar in bars_lta:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title('Fuel Type Distribution: Train vs Test vs LTA Stats', fontsize=16)\n",
    "    plt.xlabel('Fuel Type', fontsize=12)\n",
    "    plt.ylabel('Percentage (%)', fontsize=12)\n",
    "\n",
    "    # Set x-axis ticks to be in the center of the bars\n",
    "    plt.xticks(indices, comparison_df['fuel_type'], rotation=45)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_comparison_side_by_side_with_labels(df_train, df_test, lta_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy1i-WFWKYr0"
   },
   "source": [
    "## 4. Encode and embed the basic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wevl9ejMxQxX"
   },
   "source": [
    "### 4.1 Encoded `type_of_Vehicle`, `fuel_type` and `transmission` features using numerical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731213745132,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "-IXfy-3h51tB"
   },
   "outputs": [],
   "source": [
    "tran_train = list(df_train[\"transmission\"].unique())\n",
    "tran_map = {t: i for i, t in enumerate(tran_train)}\n",
    "\n",
    "\n",
    "def encode_type_trans(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Encode the type of vehicle and transmission into numerical values\n",
    "    \"\"\"\n",
    "    # transmission\n",
    "    df_train[\"transmission\"] = df_train[\"transmission\"].map(tran_map)\n",
    "    df_test[\"transmission\"] = df_test[\"transmission\"].map(tran_map)\n",
    "    # type of vehicle\n",
    "    type_mean = df_train.groupby(\"type_of_vehicle\")[\"price\"].mean()\n",
    "    df_train[\"type_of_vehicle\"] = df_train[\"type_of_vehicle\"].map(type_mean)\n",
    "    df_test[\"type_of_vehicle\"] = df_test[\"type_of_vehicle\"].map(type_mean)\n",
    "    # fuel type\n",
    "    fuel_mean = df_train.groupby(\"fuel_type\")[\"price\"].mean()\n",
    "    df_train[\"fuel_type\"] = df_train[\"fuel_type\"].map(fuel_mean)\n",
    "    df_test[\"fuel_type\"] = df_test[\"fuel_type\"].map(fuel_mean)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "df_train, df_test = encode_type_trans(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MC0ZOWz-Ejf"
   },
   "source": [
    "### 4.2 Encode the `category` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1731213845771,
     "user": {
      "displayName": "Riley",
      "userId": "12317093338567253542"
     },
     "user_tz": -480
    },
    "id": "eObdQ8us51tK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def multi_label_category(df, n_components=3):\n",
    "    \"\"\"\n",
    "    Convert the category feature into multi-label format\n",
    "    \"\"\"\n",
    "    df.loc[:, \"category_list\"] = df[\"category\"].apply(lambda x: x.split(', '))\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    category_encoded = mlb.fit_transform(df[\"category_list\"])\n",
    "    category_df = pd.DataFrame(category_encoded, columns=mlb.classes_)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    category_df = pca.fit_transform(category_df)\n",
    "    category_df = pd.DataFrame(category_df, columns=[f\"category_{i}\" for i in range(n_components)])\n",
    "    df = pd.concat([df, category_df], axis=1)\n",
    "    df.drop([\"category\", \"category_list\"],\n",
    "            axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = multi_label_category(df_train)\n",
    "df_test = multi_label_category(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIf9A6rix9TS"
   },
   "source": [
    "### 4.3 Embed the `make` and `model` information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_make(df):\n",
    "    \"\"\"\n",
    "    Fill the missing make values by extracting the make from the title\n",
    "    \"\"\"\n",
    "\n",
    "    missing_make = df[\"make\"].isnull()\n",
    "\n",
    "    make_list = df[\"make\"].unique()\n",
    "    make_list = [str(make) for make in make_list]\n",
    "    \n",
    "    def extract_make(title):\n",
    "        # Extract the make from the title\n",
    "        potential_make = title.split(\" \")[0].lower()\n",
    "        make = None\n",
    "        for item in make_list:\n",
    "            if potential_make in item:\n",
    "                make = item\n",
    "                break\n",
    "        return make\n",
    "    \n",
    "    df.loc[missing_make, \"make\"] = df.loc[missing_make, \"title\"].apply(extract_make)\n",
    "\n",
    "    df.drop([\"listing_id\"], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = fill_make(df_train)\n",
    "df_test = fill_make(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train = set(df_train[\"make\"].unique())\n",
    "make_test = set(df_test[\"make\"].unique())\n",
    "\n",
    "unseen_train = make_test - make_train\n",
    "unseen_test = make_train - make_test\n",
    "\n",
    "# Change the make \"maybach\" in the test set to \"mercedes-benz\"\n",
    "df_test[\"make\"] = df_test[\"make\"].replace(\"maybach\", \"mercedes-benz\")\n",
    "\n",
    "# Change all the other unseen makes to \"other\", both in the train and test sets\n",
    "df_train.loc[df_train[\"make\"].isin(unseen_test), \"make\"] = \"other\"\n",
    "df_test.loc[df_test[\"make\"].isin(unseen_train), \"make\"] = \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_make_model(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Encode both make and model features using target encoding with the mean of the `price` feature.\n",
    "    \"\"\"\n",
    "    # Calculate the mean price for each (make, model) combination in df_train\n",
    "    # TODO: mean is not accurate enough\n",
    "    make_model_mean = df_train.groupby([\"make\", \"model\"])[\"price\"].mean()\n",
    "    \n",
    "    # Encode the make and model in both df_train and df_test based on make_model_mean\n",
    "    df_train[\"model_encoded\"] = df_train.set_index([\"make\", \"model\"]).index.map(make_model_mean)\n",
    "    df_test[\"model_encoded\"] = df_test.set_index([\"make\", \"model\"]).index.map(make_model_mean)\n",
    "    \n",
    "    # Handle missing model matches in df_test by using the mean price for each make\n",
    "    make_mean = df_train.groupby(\"make\")[\"price\"].mean()\n",
    "    \n",
    "    # Fill missing model encodings in df_test with mean price of each make\n",
    "    df_test[\"model_encoded\"] = df_test[\"model_encoded\"].fillna(df_test[\"make\"].map(make_mean))\n",
    "    \n",
    "    #  Finally, encode `make` alone as a fallback (only for unmatched makes in `df_test`)\n",
    "    df_train[\"make_encoded\"] = df_train[\"make\"].map(make_mean)\n",
    "    df_test[\"make_encoded\"] = df_test[\"make\"].map(make_mean)\n",
    "\n",
    "    df_train.drop([\"title\", \"make\", \"model\"], axis=1, inplace=True)\n",
    "    df_test.drop([\"title\", \"make\", \"model\"], axis=1, inplace=True)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Apply the encoding function\n",
    "df_train, df_test = encode_make_model(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfEJYjMjyHLb"
   },
   "source": [
    "### 4.4 Extract key information in free texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_free_text(df, n_components=3):\n",
    "    # Define keywords for each column\n",
    "    description_keywords = {\n",
    "        'owner_info': r'(?:1 owner|single owner|2 owners)',\n",
    "        'low_mileage': r'(?:low mileage|genuine low mileage|\\b\\d+\\s?(?:km|miles)\\b)',\n",
    "        'maintenance_record': r'(?:no repairs needed|wear and tear done up|accident free|well maintained)',\n",
    "        'financing_options': r'(?:high loan|full loan available|in-house loan|bank loan)',\n",
    "        'warranty_info': r'(?:under warranty|warranty till \\d{4}|extended warranty available)',\n",
    "        'vehicle_condition': r'(?:pristine condition|excellent condition|accident free|brand new paintwork|clean interior)',\n",
    "        'vehicle_features': r'(?:sunroof|leather seats|infotainment system|sport rims|premium interior)',\n",
    "        'vehicle_type_specs': r'(?:MPV|SUV|sedan|turbo engine|\\d+\\.\\d+L engine)',\n",
    "        'fuel_efficiency': r'(?:fuel efficient|good fuel consumption|\\d+km/L)',\n",
    "        'maintenance_insurance': r'(?:fully serviced|service record|insurance available|maintenance records)'\n",
    "    }\n",
    "\n",
    "    features_keywords = {\n",
    "        'engine_specs': r'(?:\\d+\\.\\d+L|V6|4 Cylinder Inline|Twin Turbo|DOHC VVT)',\n",
    "        'power_torque': r'(?:\\d+bhp|\\d+Nm)',\n",
    "        'transmission': r'(?:\\d+ Speed|7g-Tronic|ZF)',\n",
    "        'drive_type': r'(?:FWD|AWD|RWD)',\n",
    "        'safety_airbags': r'(?:SRS Airbags)',\n",
    "        'anti_lock_brakes': r'(?:ABS|Traction Control)',\n",
    "        'cruise_control': r'(?:Cruise Control|Adaptive Cruise Control)',\n",
    "        'collision_lane_assist': r'(?:Lane Departure Warning|Collision Prevention Assist)',\n",
    "        'fuel_efficiency': r'(?:\\d+km/L)',\n",
    "        'other_features': r'(?:Keyless Entry|Paddle Shifters|Auto Headlights|Sunroof|Electric Tailgate)'\n",
    "    }\n",
    "\n",
    "    accessories_keywords = {\n",
    "        'seat_features': r'(?:leather seats|memory seats|ventilated seats|electric seats|adjustable seats)',\n",
    "        'entertainment': r'(?:audio system|bluetooth|Apple CarPlay|Android Auto|navigation|GPS|touchscreen|infotainment system)',\n",
    "        'climate_control': r'(?:rear aircon|climate control|dual-zone climate control|air conditioning)',\n",
    "        'camera_sensors': r'(?:reverse camera|front/rear camera|360 camera|parking sensors|blind spot monitor)',\n",
    "        'driving_assist': r'(?:cruise control|paddle shifters|multi-function steering|heads-up display)',\n",
    "        'wheels_rims': r'(?:sports rims|alloy rims|forged wheels|\\d+\" rims)',\n",
    "        'roof_sunroof': r'(?:sunroof|panoramic roof|moonroof)',\n",
    "        'body_kit': r'(?:body kit|spoiler|carbon fiber|side skirts)',\n",
    "        'lighting_system': r'(?:LED headlights|daytime running lights|fog lights|xenon headlights)',\n",
    "        'assist_features': r'(?:lane keeping assist|collision warning|adaptive cruise control|park assist|lane departure alert)',\n",
    "        'brakes_suspension': r'(?:big brake kit|Brembo brakes|adaptive suspension|coilover|shock absorbers)',\n",
    "        'keyless_trunk': r'(?:keyless entry|push start|remote start|electric tailgate|power tailgate|auto tailgate)',\n",
    "        'ambient_lighting': r'(?:ambient lighting|premium upholstery|interior lighting)'\n",
    "    }\n",
    "    \n",
    "    # Helper function to apply keyword matching and create binary columns\n",
    "    def apply_keyword_flags(df, column_name, keyword_dict, n_components=n_components):\n",
    "        # include pca to reduce the dimensionality of the features\n",
    "        pca = PCA(n_components=n_components)\n",
    "        keyword_df = pd.DataFrame()\n",
    "        for feature_name, pattern in keyword_dict.items():\n",
    "            # Create a binary column for each feature based on presence of keyword pattern\n",
    "            keyword_df[f'{column_name}_{feature_name}'] = df[column_name].str.contains(pattern, case=False, na=False).astype(int)\n",
    "        keyword_df = pca.fit_transform(keyword_df)\n",
    "        keyword_df = pd.DataFrame(keyword_df, columns=[f\"{column_name}_pca_{i}\" for i in range(n_components)])\n",
    "        df = pd.concat([df, keyword_df], axis=1)\n",
    "        return df\n",
    "\n",
    "    # Apply the helper function to each column with its respective keyword dictionary\n",
    "    df = apply_keyword_flags(df, \"description\", description_keywords)\n",
    "    df = apply_keyword_flags(df, \"features\", features_keywords)\n",
    "    df = apply_keyword_flags(df, \"accessories\", accessories_keywords)\n",
    "\n",
    "    # Drop the original text columns\n",
    "    df.drop([\"description\", \"features\", \"accessories\"], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = extract_free_text(df_train)\n",
    "df_test = extract_free_text(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPvDukAb51tH"
   },
   "source": [
    "### 4.5 Save the basic features encoded dataset to new CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHnT3gUj51tH"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(\"data/train_basic_encoded.csv\", index=False)\n",
    "df_test.to_csv(\"data/test_basic_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWf8Vq-LHKvJ"
   },
   "source": [
    "## Exploration: extracting highly related features for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a16PxKPfovVc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"data/train_basic_encoded.csv\")\n",
    "df_test = pd.read_csv(\"data/test_basic_encoded.csv\")\n",
    "\n",
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of the correlation matrix for the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Calculate the correlation matrix for the numerical features\n",
    "    correlation_matrix = df.corr()\n",
    "\n",
    "    # Set the style for the plot\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, cbar_kws={'shrink': 0.75})\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Correlation Matrix', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (replace df_train with your actual DataFrame):\n",
    "plot_correlation_matrix(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNmINRloGJYJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def normalize_correlation_scores_with_minimum(df, min_value=0.1, exponent=4):\n",
    "    \"\"\"\n",
    "    Normalize the correlation scores to a range between min_value and 1.\n",
    "\n",
    "    Parameters:\n",
    "    - correlation_list: List of tuples (feature_name, correlation_score).\n",
    "    - min_value: The minimum value that should correspond to no extra weightage (default is 0.5).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with feature names as keys and normalized correlation scores as values.\n",
    "    \"\"\"\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    # Get the indices of the upper triangle of the correlation matrix (excluding diagonal)\n",
    "    upper_triangle_indices = np.triu_indices_from(corr_matrix, k=1)\n",
    "\n",
    "    # Find feature pairs with correlation greater than the threshold\n",
    "    highly_correlated = [\n",
    "        (corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j])\n",
    "        for i, j in zip(*upper_triangle_indices)]\n",
    "\n",
    "    # Flatten the list of feature pairs and their correlation scores\n",
    "    flat_list = [(feature, corr_score) for feature, _, corr_score in highly_correlated]\n",
    "\n",
    "    # Extract the correlation scores\n",
    "    correlation_scores = [score for _, score in flat_list]\n",
    "\n",
    "    # Reshape for MinMaxScaler\n",
    "    correlation_scores = np.array(correlation_scores).reshape(-1, 1)\n",
    "\n",
    "    # Initialize MinMaxScaler to normalize between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_scores = scaler.fit_transform(correlation_scores).flatten()\n",
    "\n",
    "    # Apply exponent to increase separation and adjust to min_value\n",
    "    adjusted_scores = min_value + ((normalized_scores ** exponent) * (1 - min_value))\n",
    "\n",
    "    # Create the normalized feature-weight dictionary\n",
    "    normalized_weights = {feature: round(adjusted_score,4) for (feature, _), adjusted_score in zip(flat_list, adjusted_scores)}\n",
    "\n",
    "    return normalized_weights\n",
    "\n",
    "# Normalize the correlation scores with a minimum value of 0.5\n",
    "normalized_weights = normalize_correlation_scores_with_minimum(df_train)\n",
    "\n",
    "# Output the normalized feature weights\n",
    "print(normalized_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9AwZEvn51tL"
   },
   "source": [
    "## 5. Process features utilizing clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS9Ix3Qff3zF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from math import floor\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"data/train_basic_encoded.csv\")\n",
    "df_test = pd.read_csv(\"data/test_basic_encoded.csv\")\n",
    "\n",
    "\n",
    "def fill_missing_with_kmeans(df, group_col, value_col, n_clusters):\n",
    "    \"\"\"\n",
    "    Fill missing values in a DataFrame using KMeans clustering.\n",
    "    \"\"\"\n",
    "    # Separate the data into groups\n",
    "    filled_df = df.copy()\n",
    "\n",
    "    # Loop over each group\n",
    "    for _, group_df in filled_df.groupby(group_col):\n",
    "        # Get non-missing values\n",
    "        non_missing = group_df.groupby(group_col)[value_col].mean().dropna()\n",
    "\n",
    "        # If there are enough non-missing values to perform clustering\n",
    "        if len(non_missing) >= n_clusters:\n",
    "            # Prepare data for KMeans\n",
    "            kmeans_input = non_missing.values.reshape(-1, 1)\n",
    "\n",
    "            # Step 2: Apply K-Means\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            kmeans.fit(kmeans_input)\n",
    "\n",
    "            # Step 3: Create a DataFrame for the clusters\n",
    "            group_df['cluster'] = kmeans.labels_\n",
    "            cluster_means = group_df.groupby('cluster')[value_col].mean()\n",
    "\n",
    "            # Step 4: Assign the mean of the cluster to missing values\n",
    "            for i in range(len(group_df)):\n",
    "                if pd.isnull(group_df.iloc[i][value_col]):\n",
    "                    cluster_id = group_df.iloc[i]['cluster']\n",
    "                    filled_df.loc[filled_df.index[i], value_col] = cluster_means[cluster_id]\n",
    "\n",
    "        else:\n",
    "            # If not enough data, simply fill missing values with the overall mean of the group\n",
    "            mean_value = group_df[value_col].mean()\n",
    "            filled_df[value_col] = filled_df[value_col].fillna(mean_value)\n",
    "\n",
    "    # Drop the cluster column as it is no longer needed\n",
    "    filled_df.drop(columns=['cluster'], errors='ignore', inplace=True)\n",
    "\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YG266UKDf3zH"
   },
   "source": [
    "### 5.1 Fill the missing values in the features related to the vehicle's condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQi6daNwf3zI"
   },
   "outputs": [],
   "source": [
    "def fill_condition_feature(df):\n",
    "    \"\"\"\n",
    "    Fill missing values in curb_weight, power, engine_cap, omv, arf with KMeans\n",
    "    clustering based on manufactured, reg_age, type_of_vehicle, transmission\n",
    "    \"\"\"\n",
    "    group_cols = [\"manufactured\", \"reg_age\", \"type_of_vehicle\", \"transmission\", \"make_encoded\", \"model_encoded\"]\n",
    "    value_cols = [\"curb_weight\", \"power\", \"engine_cap\", \"omv\", \"arf\"]\n",
    "    for value in value_cols:\n",
    "        max_corr = 0\n",
    "        for group in group_cols:\n",
    "            corr = df[group].corr(df[value])\n",
    "            if abs(corr) > abs(max_corr):\n",
    "                max_corr = corr\n",
    "                max_group = group\n",
    "        clus_num = 5\n",
    "        if df[max_group].nunique() < 5:\n",
    "            clus_num = df[value].nunique()\n",
    "        df = fill_missing_with_kmeans(df, max_group, value, clus_num)\n",
    "    return df\n",
    "\n",
    "df_train = fill_condition_feature(df_train)\n",
    "df_test = fill_condition_feature(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI0l8eJRf3zJ"
   },
   "source": [
    "### 5.2 Fill the missing values in the features related to the vehicle's age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXZzgKwP8K_U"
   },
   "outputs": [],
   "source": [
    "def fill_age_feature(df):\n",
    "    \"\"\"\n",
    "    Fill missing values in no_of_owners, depreciation, road_tax,\n",
    "    dereg_value, mileage with KMeans\n",
    "    \"\"\"\n",
    "    group_cols = [\"manufactured\", \"reg_age\", \"type_of_vehicle\", \"transmission\", \"make_encoded\",\n",
    "                  \"model_encoded\", \"curb_weight\", \"power\", \"engine_cap\", \"omv\", \"arf\"]\n",
    "    value_cols = [\"no_of_owners\", \"depreciation\", \"road_tax\", \"dereg_value\", \"mileage\"]\n",
    "    for value in value_cols:\n",
    "        max_corr = 0\n",
    "        for group in group_cols:\n",
    "            corr = df[group].corr(df[value])\n",
    "            if abs(corr) > abs(max_corr):\n",
    "                max_corr = corr\n",
    "                max_group = group\n",
    "        clus_num = 5\n",
    "        if max_group == \"no_of_owners\":\n",
    "            clus_num = 3\n",
    "        df = fill_missing_with_kmeans(df, max_group, value, clus_num)\n",
    "        if value == \"no_of_owners\":\n",
    "            df[\"no_of_owners\"] = df[\"no_of_owners\"].apply(lambda x: floor(x))\n",
    "    return df\n",
    "\n",
    "df_train = fill_age_feature(df_train)\n",
    "df_test = fill_age_feature(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBkO68SHf3zL"
   },
   "source": [
    "### 5.3 Save the processed dataset to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qs7qBqDff3zM"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(\"data/train_processed.csv\", index=False)\n",
    "df_test.to_csv(\"data/test_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oINx_eaq51tQ"
   },
   "source": [
    "# Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_Vl-BVfOYk8"
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "for k,v in normalized_weights.items():\n",
    "    weights.append(v)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6Q18GAE2mT3"
   },
   "source": [
    "## 6.1 XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KX8f3Z9Qf3zN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os\n",
    "\n",
    "\n",
    "def train_test_xgboost(df_train, df_test, n_estimators=2000, learning_rate=0.2, max_depth=4, random_state=0):\n",
    "    \"\"\"\n",
    "    Train an XGBoost model on the given DataFrame and return the average RMSE score.\n",
    "    \"\"\"\n",
    "    # Define features (X) and target (y)\n",
    "    X = df_train.drop(\"price\", axis=1)\n",
    "    y = df_train[\"price\"]\n",
    "\n",
    "    # XGBoost model parameters\n",
    "    xgb_params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"random_state\": random_state,\n",
    "    }\n",
    "    model = XGBRegressor(**xgb_params)\n",
    "\n",
    "    # Setting up cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Cross-validation with early stopping\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False,\n",
    "            # feature_weights = weights\n",
    "        )\n",
    "\n",
    "        # Predict and calculate validation RMSE\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        val_scores.append(rmse)\n",
    "\n",
    "    print(\"Each Validation RMSE:\", end=\"\")\n",
    "    for score in val_scores:\n",
    "        print(f\" {score:.2f}\", end=\", \")\n",
    "    print()\n",
    "    print(\"Average Validation RMSE:\", np.mean(val_scores))\n",
    "\n",
    "    # predict the price\n",
    "    X_test = df_test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    id_list = list(range(len(y_pred)))\n",
    "    submission = pd.DataFrame({\"Id\": id_list, \"Predicted\": y_pred})\n",
    "    if not os.path.exists(\"result/xgboost\"):\n",
    "        os.makedirs(\"result/xgboost\")\n",
    "    submission.to_csv(f\"result/xgboost/xgboost_n{n_estimators}_lr{learning_rate}_dpt{max_depth}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58_FNXgm51tR"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_processed.csv\")\n",
    "df_test = pd.read_csv(\"data/test_processed.csv\")\n",
    "\n",
    "train_test_xgboost(df_train, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os\n",
    "\n",
    "\n",
    "def train_test_lightgbm(df_train, df_test, n_estimators=2000, learning_rate=0.1, max_depth=5, random_state=0):\n",
    "    \"\"\"\n",
    "    Train a LightGBM model on the given DataFrame and return the average RMSE score.\n",
    "    \"\"\"\n",
    "    # Define features (X) and target (y)\n",
    "    X = df_train.drop(\"price\", axis=1)\n",
    "    y = df_train[\"price\"]\n",
    "\n",
    "    # LightGBM model parameters\n",
    "    lgbm_params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"random_state\": random_state,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "    model = LGBMRegressor(**lgbm_params)\n",
    "\n",
    "    # Setting up cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Cross-validation with early stopping\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "        )\n",
    "\n",
    "        # Predict and calculate validation RMSE\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        val_scores.append(rmse)\n",
    "\n",
    "    print(\"Each Validation RMSE:\", end=\"\")\n",
    "    for score in val_scores:\n",
    "        print(f\" {score:.2f}\", end=\", \")\n",
    "    print()\n",
    "    print(\"Average Validation RMSE:\", np.mean(val_scores))\n",
    "\n",
    "    # Predict the price on the test set\n",
    "    X_test = df_test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    id_list = list(range(len(y_pred)))\n",
    "    submission = pd.DataFrame({\"Id\": id_list, \"Predicted\": y_pred})\n",
    "    if not os.path.exists(\"result/lightgbm\"):\n",
    "        os.makedirs(\"result/lightgbm\")\n",
    "    submission.to_csv(f\"result/lightgbm/lightgbm_n{n_estimators}_lr{learning_rate}_dpt{max_depth}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_processed.csv\")\n",
    "df_test = pd.read_csv(\"data/test_processed.csv\")\n",
    "\n",
    "train_test_lightgbm(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import os\n",
    "\n",
    "\n",
    "def train_test_random_forest(df_train, df_test, n_estimators=100, max_depth=15, random_state=0):\n",
    "    \"\"\"\n",
    "    Train a Random Forest model on the given DataFrame and return the average RMSE score.\n",
    "    \"\"\"\n",
    "    # Define features (X) and target (y)\n",
    "    X = df_train.drop(\"price\", axis=1)\n",
    "    y = df_train[\"price\"]\n",
    "\n",
    "    # Random Forest model parameters\n",
    "    rf_params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"random_state\": random_state,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    model = RandomForestRegressor(**rf_params)\n",
    "\n",
    "    # Setting up cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Cross-validation loop to calculate validation RMSE\n",
    "    val_scores = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and calculate validation RMSE\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        val_scores.append(rmse)\n",
    "\n",
    "    print(\"Each Validation RMSE:\", end=\"\")\n",
    "    for score in val_scores:\n",
    "        print(f\" {score:.2f}\", end=\", \")\n",
    "    print()\n",
    "    print(\"Average Validation RMSE:\", np.mean(val_scores))\n",
    "\n",
    "    # Predict on test data\n",
    "    X_test = df_test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    id_list = list(range(len(y_pred)))\n",
    "    submission = pd.DataFrame({\"Id\": id_list, \"Predicted\": y_pred})\n",
    "    if not os.path.exists(\"result/random_forest\"):\n",
    "        os.makedirs(\"result/random_forest\")\n",
    "    submission.to_csv(f\"result/random_forest/random_forest_n{n_estimators}_dpt{max_depth}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_processed.csv\")\n",
    "df_test = pd.read_csv(\"data/test_processed.csv\")\n",
    "\n",
    "for n in [100, 200, 300]:\n",
    "    for d in [5, 10, 15]:\n",
    "        print(f\"### Training Random Forest with n_estimators={n}, max_depth={d} ###\")\n",
    "        train_test_random_forest(df_train, df_test, n_estimators=n, max_depth=d)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "class Reg_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.y = torch.tensor(y).squeeze()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "\n",
    "class Reg_MLP(nn.Module):\n",
    "    def __init__(self, n_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_test_mlp(df_train, df_test):\n",
    "    torch.manual_seed(0)\n",
    "    torch.random.manual_seed(0)\n",
    "\n",
    "    X = df_train.drop(\"price\", axis=1).to_numpy(dtype=np.float32)\n",
    "    y = df_train[\"price\"].to_numpy(dtype=np.float32)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    train_dataset = Reg_Dataset(X_train, y_train)\n",
    "    val_dataset = Reg_Dataset(X_val, y_val)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Reg_MLP(X_train.shape[1]).to(DEVICE)\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    EPOCH = 1\n",
    "    PATIENCE = 10\n",
    "    best_val_loss = float(\"inf\")\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(EPOCH):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            del inputs, labels, outputs, loss\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss.append(loss.item())\n",
    "                del inputs, labels, outputs, loss\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_train_loss = np.sqrt(np.mean(train_loss))\n",
    "        avg_val_loss = np.sqrt(np.mean(val_loss))\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Epoch {i+1}/{EPOCH} -- train loss: {avg_train_loss:.4f}, val loss: {avg_val_loss:.4f} \")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt += 1\n",
    "            if cnt >= PATIENCE:\n",
    "                print(f\"\\n*****  Early Stop at Epoch {i + 1}  *****\\n\")\n",
    "                break\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        groundtruth = []\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            groundtruth.extend(labels.squeeze().tolist())\n",
    "            del inputs, labels, outputs\n",
    "\n",
    "    save_dir = \"models/\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, \"mlp_weights.pth\"))\n",
    "\n",
    "    predictions = np.asarray(predictions)\n",
    "    groundtruth = np.asarray(groundtruth)\n",
    "\n",
    "    valid_rmse = np.sqrt(np.mean((predictions - groundtruth) ** 2))\n",
    "    print(\"\\nMulti-layer Perceptron Regression\")\n",
    "    print(f\" - Validation RMSE: {valid_rmse:.4f}\")\n",
    "\n",
    "    X_test = df_test.to_numpy(dtype=np.float32)\n",
    "    test_dataset = Reg_Dataset(X_test, np.zeros(X_test.shape[0]))\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            predictions.extend(outputs.tolist())\n",
    "            del inputs, outputs\n",
    "    \n",
    "    predictions = np.asarray(predictions)\n",
    "    id_list = list(range(len(predictions)))\n",
    "    submission = pd.DataFrame({\"Id\": id_list, \"Predicted\": predictions})\n",
    "    if not os.path.exists(\"result/mlp\"):\n",
    "        os.makedirs(\"result/mlp\")\n",
    "    submission.to_csv(\"result/mlp/mlp_submission.csv\", index=False)\n",
    "\n",
    "    del model, criterion, optimizer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train_processed.csv\")\n",
    "df_test = pd.read_csv(\"data/test_processed.csv\")\n",
    "\n",
    "train_test_mlp(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cs5228",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
